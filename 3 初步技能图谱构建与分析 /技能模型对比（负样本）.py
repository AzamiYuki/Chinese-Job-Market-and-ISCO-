import pandas as pd
import numpy as np
import json
import networkx as nx
from collections import defaultdict
import random
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score
from sklearn.metrics.pairwise import cosine_similarity
import warnings
import time
from typing import Dict, List, Tuple
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# å°è¯•å¯¼å…¥node2vec
try:
    from node2vec import Node2Vec
    NODE2VEC_AVAILABLE = True
except ImportError:
    NODE2VEC_AVAILABLE = False

class RatioAnalysisSystem:
    def __init__(self, csv_file: str, random_seed: int = 42):
        """
        æ­£è´Ÿè¾¹æ¯”ä¾‹åˆ†æç³»ç»Ÿ
        
        Args:
            csv_file: åŒ–ç®€åçš„æŠ€èƒ½æ•°æ®CSVæ–‡ä»¶
            random_seed: éšæœºç§å­
        """
        self.csv_file = csv_file
        self.random_seed = random_seed
        random.seed(random_seed)
        np.random.seed(random_seed)
        
        # å›¾ç»“æ„
        self.full_graph = nx.Graph()
        self.training_graph = nx.Graph()
        
        # èŠ‚ç‚¹ä¿¡æ¯
        self.skill_nodes = set()
        self.job_nodes = set()
        
        # å›ºå®šçš„æ­£æ ·æœ¬ï¼ˆç¡®ä¿æ¯”è¾ƒå…¬å¹³æ€§ï¼‰
        self.fixed_positive_samples = []
        self.negative_candidate_pool = []
        
        # ç®—æ³•æ¨¡å‹
        self.pa_node_degrees = {}
        self.node2vec_model = None
        
        # åˆ†æç»“æœ
        self.ratio_results = []
        
        print(f"æ­£è´Ÿè¾¹æ¯”ä¾‹åˆ†æç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def load_data_and_setup(self) -> Dict:
        """åŠ è½½æ•°æ®å¹¶è®¾ç½®åŸºç¡€å›¾ç»“æ„"""
        print("æ­£åœ¨åŠ è½½æ•°æ®å¹¶æ„å»ºå›¾ç»“æ„...")
        
        df = pd.read_csv(self.csv_file)
        edge_weights = defaultdict(int)
        
        # æ„å»ºå›¾
        for idx, row in df.iterrows():
            if idx % 5000 == 0:
                print(f"å¤„ç†è¿›åº¦: {idx}/{len(df)}")
            
            isco_code = row.get('ISCO_4_Digit_Code_Gemini')
            if pd.isna(isco_code):
                continue
            
            job_node = f"JOB_{int(isco_code)}"
            self.job_nodes.add(job_node)
            
            skills_str = row.get('æ ‡å‡†åŒ–æŠ€èƒ½', '[]')
            try:
                skills = json.loads(skills_str)
            except:
                continue
            
            for skill in skills:
                if skill and len(skill.strip()) > 1:
                    skill_node = f"SKILL_{skill.strip()}"
                    self.skill_nodes.add(skill_node)
                    edge = (skill_node, job_node)
                    edge_weights[edge] += 1
        
        # æ„å»ºå®Œæ•´å›¾
        for (skill_node, job_node), weight in edge_weights.items():
            self.full_graph.add_edge(skill_node, job_node, weight=weight)
        
        # æ·»åŠ èŠ‚ç‚¹ç±»å‹
        for skill_node in self.skill_nodes:
            self.full_graph.add_node(skill_node, node_type='skill')
        for job_node in self.job_nodes:
            self.full_graph.add_node(job_node, node_type='job')
        
        stats = {
            'total_nodes': len(self.skill_nodes) + len(self.job_nodes),
            'skill_nodes': len(self.skill_nodes),
            'job_nodes': len(self.job_nodes),
            'total_edges': len(edge_weights)
        }
        
        print(f"âœ“ å›¾ç»“æ„æ„å»ºå®Œæˆ:")
        print(f"  èŠ‚ç‚¹æ•°: {stats['total_nodes']} ({stats['skill_nodes']}æŠ€èƒ½ + {stats['job_nodes']}èŒä¸š)")
        print(f"  è¾¹æ•°: {stats['total_edges']}")
        
        return stats
    
    def prepare_training_data(self, sample_size: int = 2000):
        """å‡†å¤‡è®­ç»ƒæ•°æ®å’Œæ­£æ ·æœ¬"""
        print(f"æ­£åœ¨å‡†å¤‡è®­ç»ƒæ•°æ®ï¼ˆæ­£æ ·æœ¬æ•°é‡: {sample_size}ï¼‰...")
        
        # è·å–æ‰€æœ‰è¾¹ä½œä¸ºæ­£æ ·æœ¬å€™é€‰
        all_edges = list(self.full_graph.edges())
        
        # éšæœºé‡‡æ ·å›ºå®šæ•°é‡çš„æ­£æ ·æœ¬ï¼ˆç¡®ä¿åç»­æ¯”è¾ƒçš„å…¬å¹³æ€§ï¼‰
        if len(all_edges) > sample_size:
            self.fixed_positive_samples = random.sample(all_edges, sample_size)
        else:
            self.fixed_positive_samples = all_edges
        
        # æ„å»ºè®­ç»ƒå›¾ï¼ˆç”¨äºè®¡ç®—èŠ‚ç‚¹åº¦æ•°å’Œè®­ç»ƒNode2Vecï¼‰
        # ä½¿ç”¨80%çš„æ­£æ ·æœ¬ä½œä¸ºè®­ç»ƒæ•°æ®
        train_edge_count = int(len(self.fixed_positive_samples) * 0.8)
        train_edges = self.fixed_positive_samples[:train_edge_count]
        
        self.training_graph.clear()
        for node in self.full_graph.nodes(data=True):
            self.training_graph.add_node(node[0], **node[1])
        
        for edge in train_edges:
            if self.full_graph.has_edge(edge[0], edge[1]):
                weight = self.full_graph[edge[0]][edge[1]]['weight']
                self.training_graph.add_edge(edge[0], edge[1], weight=weight)
        
        # ç”Ÿæˆè´Ÿæ ·æœ¬å€™é€‰æ± 
        existing_edges = set(self.full_graph.edges())
        self.negative_candidate_pool = []
        
        for skill_node in self.skill_nodes:
            for job_node in self.job_nodes:
                if (skill_node, job_node) not in existing_edges and (job_node, skill_node) not in existing_edges:
                    self.negative_candidate_pool.append((skill_node, job_node))
        
        random.shuffle(self.negative_candidate_pool)
        
        print(f"âœ“ è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ:")
        print(f"  å›ºå®šæ­£æ ·æœ¬æ•°: {len(self.fixed_positive_samples)}")
        print(f"  è®­ç»ƒè¾¹æ•°: {len(train_edges)}")
        print(f"  è´Ÿæ ·æœ¬å€™é€‰æ± : {len(self.negative_candidate_pool)}")
    
    def train_algorithms(self):
        """è®­ç»ƒPAå’ŒNode2Vecç®—æ³•"""
        print("æ­£åœ¨è®­ç»ƒç®—æ³•...")
        
        # 1. è®¡ç®—PAç®—æ³•çš„èŠ‚ç‚¹åº¦æ•°
        self.pa_node_degrees = dict(self.training_graph.degree())
        print(f"âœ“ PAç®—æ³•å‡†å¤‡å®Œæˆï¼ˆåŸºäºè®­ç»ƒå›¾åº¦æ•°ï¼‰")
        
        # 2. è®­ç»ƒNode2Vecæ¨¡å‹
        if NODE2VEC_AVAILABLE and len(self.training_graph.edges()) > 0:
            try:
                # ä½¿ç”¨ä¼˜åŒ–çš„å‚æ•°ï¼ˆåŸºäºä¹‹å‰çš„ç½‘æ ¼æœç´¢ç»“æœï¼‰
                node2vec = Node2Vec(
                    self.training_graph,
                    dimensions=64,      # é€‚ä¸­çš„ç»´åº¦
                    walk_length=16,       # è¾ƒé•¿çš„æ¸¸èµ°
                    num_walks=100,       # é€‚ä¸­çš„æ¸¸èµ°æ¬¡æ•°
                    p=2,                 # å¹³è¡¡å‚æ•°
                    q=0.5,                 # åå‘DFS
                    workers=4,
                    seed=self.random_seed
                )
                
                self.node2vec_model = node2vec.fit(
                    window=10,
                    min_count=1,
                    batch_words=4,
                    sg=1,
                    epochs=10
                )
                
                print(f"âœ“ Node2Vecæ¨¡å‹è®­ç»ƒå®Œæˆ")
                
            except Exception as e:
                print(f"Node2Vecè®­ç»ƒå¤±è´¥: {e}")
                self.node2vec_model = None
        else:
            print(f"âš Node2Vecä¸å¯ç”¨ï¼ˆåº“æœªå®‰è£…æˆ–è®­ç»ƒå›¾ä¸ºç©ºï¼‰")
            self.node2vec_model = None
    
    def calculate_pa_scores(self, edge_list: List[Tuple]) -> List[float]:
        """è®¡ç®—PAç®—æ³•å¾—åˆ†"""
        scores = []
        for u, v in edge_list:
            degree_u = self.pa_node_degrees.get(u, 0)
            degree_v = self.pa_node_degrees.get(v, 0)
            pa_score = degree_u * degree_v
            scores.append(pa_score)
        return scores
    
    def calculate_node2vec_scores(self, edge_list: List[Tuple]) -> List[float]:
        """è®¡ç®—Node2Vecç®—æ³•å¾—åˆ†"""
        if not self.node2vec_model:
            return [0.0] * len(edge_list)  # å¦‚æœæ¨¡å‹ä¸å¯ç”¨ï¼Œè¿”å›é›¶åˆ†
        
        scores = []
        for u, v in edge_list:
            try:
                if u in self.node2vec_model.wv and v in self.node2vec_model.wv:
                    emb_u = self.node2vec_model.wv[u]
                    emb_v = self.node2vec_model.wv[v]
                    similarity = cosine_similarity([emb_u], [emb_v])[0][0]
                    scores.append(similarity)
                else:
                    scores.append(0.0)
            except:
                scores.append(0.0)
        return scores
    
    def evaluate_at_ratio(self, negative_ratio: int) -> Dict:
        """åœ¨æŒ‡å®šè´Ÿæ ·æœ¬æ¯”ä¾‹ä¸‹è¯„ä¼°ç®—æ³•æ€§èƒ½"""
        print(f"æ­£åœ¨è¯„ä¼° 1:{negative_ratio} æ¯”ä¾‹...")
        
        # ä½¿ç”¨å›ºå®šçš„æ­£æ ·æœ¬
        positive_samples = self.fixed_positive_samples.copy()
        positive_count = len(positive_samples)
        
        # æ ¹æ®æ¯”ä¾‹é‡‡æ ·è´Ÿæ ·æœ¬
        negative_count = positive_count * negative_ratio
        if negative_count > len(self.negative_candidate_pool):
            negative_samples = self.negative_candidate_pool.copy()
            # å¦‚æœå€™é€‰æ± ä¸å¤Ÿï¼Œè¿›è¡Œé‡å¤é‡‡æ ·
            additional_needed = negative_count - len(self.negative_candidate_pool)
            additional_samples = random.choices(self.negative_candidate_pool, k=additional_needed)
            negative_samples.extend(additional_samples)
        else:
            negative_samples = random.sample(self.negative_candidate_pool, negative_count)
        
        # å‡†å¤‡è¯„ä¼°æ•°æ®
        all_edges = positive_samples + negative_samples
        y_true = [1] * len(positive_samples) + [0] * len(negative_samples)
        
        # è®¡ç®—PAå¾—åˆ†
        pa_scores = self.calculate_pa_scores(all_edges)
        
        # è®¡ç®—Node2Vecå¾—åˆ†
        n2v_scores = self.calculate_node2vec_scores(all_edges)
        
        # å½’ä¸€åŒ–å¾—åˆ†
        def normalize_scores(scores):
            max_score = max(scores) if scores and max(scores) > 0 else 1
            return [score / max_score for score in scores]
        
        pa_normalized = normalize_scores(pa_scores)
        n2v_normalized = normalize_scores(n2v_scores)
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        def evaluate_performance(scores, threshold=0.5):
            y_pred = (np.array(scores) >= threshold).astype(int)
            return {
                'precision': precision_score(y_true, y_pred, zero_division=0),
                'recall': recall_score(y_true, y_pred, zero_division=0),
                'f1_score': f1_score(y_true, y_pred, zero_division=0),
                'auc_roc': roc_auc_score(y_true, scores) if len(set(y_true)) > 1 else 0.5
            }
        
        pa_metrics = evaluate_performance(pa_normalized)
        n2v_metrics = evaluate_performance(n2v_normalized)
        
        result = {
            'negative_ratio': negative_ratio,
            'positive_count': positive_count,
            'negative_count': negative_count,
            'pa_metrics': pa_metrics,
            'n2v_metrics': n2v_metrics,
            'pa_f1': pa_metrics['f1_score'],
            'n2v_f1': n2v_metrics['f1_score']
        }
        
        print(f"  æ¯”ä¾‹ 1:{negative_ratio} - PA F1: {pa_metrics['f1_score']:.4f}, N2V F1: {n2v_metrics['f1_score']:.4f}")
        
        return result
    
    def run_ratio_analysis(self, max_ratio: int = 10) -> List[Dict]:
        """è¿è¡Œå®Œæ•´çš„æ¯”ä¾‹åˆ†æ"""
        print(f"\nå¼€å§‹æ­£è´Ÿè¾¹æ¯”ä¾‹åˆ†æï¼ˆ1:1 åˆ° 1:{max_ratio}ï¼‰...")
        
        self.ratio_results = []
        
        for ratio in range(1, max_ratio + 1):
            try:
                result = self.evaluate_at_ratio(ratio)
                self.ratio_results.append(result)
                
                # ä¿å­˜ä¸­é—´ç»“æœï¼ˆé˜²æ­¢é•¿æ—¶é—´è¿è¡Œä¸­æ–­ï¼‰
                if ratio % 3 == 0:
                    self._save_intermediate_results()
                    
            except Exception as e:
                print(f"æ¯”ä¾‹ 1:{ratio} è¯„ä¼°å¤±è´¥: {e}")
                continue
        
        print(f"å®Œæˆ {len(self.ratio_results)} ä¸ªæ¯”ä¾‹çš„è¯„ä¼°")
        return self.ratio_results
    
    def _save_intermediate_results(self):
        """ä¿å­˜ä¸­é—´ç»“æœ"""
        with open('ratio_analysis_intermediate.json', 'w', encoding='utf-8') as f:
            json.dump(self.ratio_results, f, ensure_ascii=False, indent=2)
    
    def plot_ratio_comparison(self, save_path: str = 'ratio_comparison.png') -> None:
        """ç»˜åˆ¶æ¯”ä¾‹å¯¹æ¯”å›¾ï¼ˆå¤ç°è®ºæ–‡å›¾4ï¼‰"""
        print("æ­£åœ¨ç»˜åˆ¶æ¯”ä¾‹å¯¹æ¯”å›¾...")
        
        if not self.ratio_results:
            print("æ²¡æœ‰åˆ†æç»“æœå¯ç»˜åˆ¶")
            return
        
        # æå–æ•°æ®
        ratios = [r['negative_ratio'] for r in self.ratio_results]
        pa_f1_scores = [r['pa_f1'] for r in self.ratio_results]
        n2v_f1_scores = [r['n2v_f1'] for r in self.ratio_results]
        
        # åˆ›å»ºå›¾è¡¨
        plt.figure(figsize=(12, 8))
        
        # ç»˜åˆ¶çº¿æ¡
        plt.plot(ratios, pa_f1_scores, 
                marker='o', linewidth=2.5, markersize=8, 
                color='#2E8B57', label='Preferential Attachment (PA)',
                markerfacecolor='white', markeredgewidth=2)
        
        plt.plot(ratios, n2v_f1_scores, 
                marker='s', linewidth=2.5, markersize=8,
                color='#FF6B35', label='Node2Vec (N2V)',
                markerfacecolor='white', markeredgewidth=2)
        
        # æ·»åŠ äº¤å‰ç‚¹æ ‡è®°
        # æ‰¾åˆ°PAå’ŒN2Væ€§èƒ½ç›¸ç­‰çš„ç‚¹
        crossover_ratio = None
        min_diff = float('inf')
        for i, ratio in enumerate(ratios):
            diff = abs(pa_f1_scores[i] - n2v_f1_scores[i])
            if diff < min_diff:
                min_diff = diff
                crossover_ratio = ratio
        
        if crossover_ratio:
            crossover_idx = ratios.index(crossover_ratio)
            crossover_f1 = (pa_f1_scores[crossover_idx] + n2v_f1_scores[crossover_idx]) / 2
            plt.plot(crossover_ratio, crossover_f1, 
                    marker='*', markersize=15, color='gold', 
                    markeredgecolor='black', markeredgewidth=1.5,
                    label=f'äº¤å‰ç‚¹ (â‰ˆ{crossover_ratio}:1)')
        
        # è®¾ç½®å›¾è¡¨æ ·å¼
        plt.xlabel('è´Ÿæ ·æœ¬ä¸æ­£æ ·æœ¬æ¯”ä¾‹', fontsize=14, fontweight='bold')
        plt.ylabel('F1-Score (æ­£æ ·æœ¬ç±»åˆ«)', fontsize=14, fontweight='bold')
        plt.title('ä¸åŒæ­£è´Ÿæ ·æœ¬æ¯”ä¾‹ä¸‹çš„ç®—æ³•æ€§èƒ½å¯¹æ¯”\n(å¤ç°è®ºæ–‡å›¾4)', 
                 fontsize=16, fontweight='bold', pad=20)
        
        # è®¾ç½®ç½‘æ ¼å’Œæ ·å¼
        plt.grid(True, alpha=0.3, linestyle='--')
        plt.legend(loc='best', fontsize=12, framealpha=0.9)
        
        # è®¾ç½®åæ ‡è½´
        plt.xlim(0.5, max(ratios) + 0.5)
        plt.ylim(0, 1.05)
        plt.xticks(ratios, [f'1:{r}' for r in ratios], rotation=45)
        
        # æ·»åŠ æ³¨é‡Š
        plt.text(0.02, 0.98, 
                f'æ ·æœ¬è§„æ¨¡: {self.ratio_results[0]["positive_count"]} æ­£æ ·æœ¬', 
                transform=plt.gca().transAxes, 
                fontsize=10, verticalalignment='top',
                bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
        
        # ç´§å‡‘å¸ƒå±€
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        plt.savefig(save_path, dpi=300, bbox_inches='tight', 
                   facecolor='white', edgecolor='none')
        plt.show()
        
        print(f"âœ“ æ¯”ä¾‹å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")
    
    def generate_analysis_report(self) -> Dict:
        """ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š"""
        print("æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        if not self.ratio_results:
            return {}
        
        # æ‰¾åˆ°å…³é”®ç‚¹
        pa_best_ratio = max(self.ratio_results, key=lambda x: x['pa_f1'])
        n2v_best_ratio = max(self.ratio_results, key=lambda x: x['n2v_f1'])
        
        # æ‰¾åˆ°äº¤å‰ç‚¹
        crossover_point = None
        min_diff = float('inf')
        for result in self.ratio_results:
            diff = abs(result['pa_f1'] - result['n2v_f1'])
            if diff < min_diff:
                min_diff = diff
                crossover_point = result
        
        # åˆ†æè¶‹åŠ¿
        ratios = [r['negative_ratio'] for r in self.ratio_results]
        pa_trend = np.polyfit(ratios, [r['pa_f1'] for r in self.ratio_results], 1)[0]
        n2v_trend = np.polyfit(ratios, [r['n2v_f1'] for r in self.ratio_results], 1)[0]
        
        report = {
            'summary': {
                'total_ratios_tested': len(self.ratio_results),
                'positive_sample_count': self.ratio_results[0]['positive_count'],
                'crossover_ratio': crossover_point['negative_ratio'] if crossover_point else None,
                'crossover_f1_diff': min_diff
            },
            'pa_performance': {
                'best_ratio': pa_best_ratio['negative_ratio'],
                'best_f1': pa_best_ratio['pa_f1'],
                'trend_slope': pa_trend,
                'performance_at_1_1': self.ratio_results[0]['pa_f1'] if self.ratio_results else None
            },
            'n2v_performance': {
                'best_ratio': n2v_best_ratio['negative_ratio'],
                'best_f1': n2v_best_ratio['n2v_f1'],
                'trend_slope': n2v_trend,
                'performance_at_1_1': self.ratio_results[0]['n2v_f1'] if self.ratio_results else None
            },
            'detailed_results': self.ratio_results
        }
        
        # æ‰“å°å…³é”®å‘ç°
        print(f"\nğŸ“Š åˆ†ææŠ¥å‘Šæ‘˜è¦:")
        print(f"  æµ‹è¯•æ¯”ä¾‹èŒƒå›´: 1:1 åˆ° 1:{max([r['negative_ratio'] for r in self.ratio_results])}")
        print(f"  æ­£æ ·æœ¬æ•°é‡: {report['summary']['positive_sample_count']:,}")
        
        if crossover_point:
            print(f"  æ€§èƒ½äº¤å‰ç‚¹: çº¦ 1:{crossover_point['negative_ratio']} (å·®å¼‚: {min_diff:.4f})")
        
        print(f"\n  PAç®—æ³•:")
        print(f"    1:1æ¯”ä¾‹F1: {report['pa_performance']['performance_at_1_1']:.4f}")
        print(f"    æœ€ä½³æ¯”ä¾‹: 1:{report['pa_performance']['best_ratio']} (F1: {report['pa_performance']['best_f1']:.4f})")
        print(f"    æ€§èƒ½è¶‹åŠ¿: {'ä¸‹é™' if pa_trend < 0 else 'ä¸Šå‡'} ({pa_trend:.4f}/æ¯”ä¾‹)")
        
        print(f"\n  Node2Vecç®—æ³•:")
        print(f"    1:1æ¯”ä¾‹F1: {report['n2v_performance']['performance_at_1_1']:.4f}")
        print(f"    æœ€ä½³æ¯”ä¾‹: 1:{report['n2v_performance']['best_ratio']} (F1: {report['n2v_performance']['best_f1']:.4f})")
        print(f"    æ€§èƒ½è¶‹åŠ¿: {'ä¸‹é™' if n2v_trend < 0 else 'ä¸Šå‡'} ({n2v_trend:.4f}/æ¯”ä¾‹)")
        
        return report
    
    def save_results(self, output_prefix: str = 'ratio_analysis'):
        """ä¿å­˜å®Œæ•´ç»“æœ"""
        print(f"æ­£åœ¨ä¿å­˜ç»“æœ...")
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_analysis_report()
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        with open(f'{output_prefix}_detailed_results.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜ç®€åŒ–çš„CSVæ ¼å¼
        if self.ratio_results:
            df_results = pd.DataFrame([
                {
                    'negative_ratio': r['negative_ratio'],
                    'ratio_label': f"1:{r['negative_ratio']}",
                    'positive_count': r['positive_count'],
                    'negative_count': r['negative_count'],
                    'pa_f1': r['pa_f1'],
                    'n2v_f1': r['n2v_f1'],
                    'pa_precision': r['pa_metrics']['precision'],
                    'pa_recall': r['pa_metrics']['recall'],
                    'n2v_precision': r['n2v_metrics']['precision'],
                    'n2v_recall': r['n2v_metrics']['recall']
                }
                for r in self.ratio_results
            ])
            
            df_results.to_csv(f'{output_prefix}_results.csv', index=False, encoding='utf-8-sig')
        


def main():
    """ä¸»å‡½æ•°ï¼šå®Œæ•´çš„æ¯”ä¾‹åˆ†ææµç¨‹"""

    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    analyzer = RatioAnalysisSystem(
        csv_file='simplified_jobs_skills.csv',
        random_seed=42
    )
    
    # æ­¥éª¤1: åŠ è½½æ•°æ®
    print("\n" + "="*60)
    print("æ­¥éª¤1: åŠ è½½æ•°æ®å¹¶æ„å»ºå›¾ç»“æ„")
    print("="*60)
    graph_stats = analyzer.load_data_and_setup()
    
    # æ­¥éª¤2: å‡†å¤‡è®­ç»ƒæ•°æ®
    print("\n" + "="*60)
    print("æ­¥éª¤2: å‡†å¤‡è®­ç»ƒæ•°æ®")
    print("="*60)
    analyzer.prepare_training_data(sample_size=2000)  # å¯è°ƒæ•´æ ·æœ¬å¤§å°
    
    # æ­¥éª¤3: è®­ç»ƒç®—æ³•
    print("\n" + "="*60)
    print("æ­¥éª¤3: è®­ç»ƒPAå’ŒNode2Vecç®—æ³•")
    print("="*60)
    analyzer.train_algorithms()
    
    # æ­¥éª¤4: è¿è¡Œæ¯”ä¾‹åˆ†æ
    print("\n" + "="*60)
    print("æ­¥éª¤4: è¿è¡Œæ­£è´Ÿè¾¹æ¯”ä¾‹åˆ†æ")
    print("="*60)
    
    # è¯¢é—®ç”¨æˆ·åˆ†æèŒƒå›´
    max_ratio = input("è¯·è¾“å…¥æœ€å¤§è´Ÿæ ·æœ¬æ¯”ä¾‹ [é»˜è®¤10ï¼Œå³æµ‹è¯•1:1åˆ°1:10]: ").strip()
    try:
        max_ratio = int(max_ratio) if max_ratio else 10
    except:
        max_ratio = 10
    
    ratio_results = analyzer.run_ratio_analysis(max_ratio=max_ratio)
    
    # æ­¥éª¤5: ç»˜åˆ¶å¯¹æ¯”å›¾
    print("\n" + "="*60)
    print("æ­¥éª¤5: ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”å›¾")
    print("="*60)
    analyzer.plot_ratio_comparison()
    
    # æ­¥éª¤6: ç”Ÿæˆåˆ†ææŠ¥å‘Š
    print("\n" + "="*60)
    print("æ­¥éª¤6: ç”Ÿæˆåˆ†ææŠ¥å‘Š")
    print("="*60)
    report = analyzer.generate_analysis_report()
    
    # æ­¥éª¤7: ä¿å­˜ç»“æœ
    print("\n" + "="*60)
    print("æ­¥éª¤7: ä¿å­˜åˆ†æç»“æœ")
    print("="*60)
    analyzer.save_results()
    
    # ç”Ÿæˆæ€»ç»“
    print("\n" + "="*80)
    print("æ­£è´Ÿè¾¹æ¯”ä¾‹åˆ†æå®Œæˆ")
    print("="*80)
    
    print(f"\nğŸ“ˆ å…³é”®å‘ç°:")
    if report and 'summary' in report:
        if report['summary']['crossover_ratio']:
            print(f"  â€¢ ç®—æ³•æ€§èƒ½äº¤å‰ç‚¹: çº¦ 1:{report['summary']['crossover_ratio']}")
            print(f"  â€¢ åœ¨ä½æ¯”ä¾‹æ—¶PAè¡¨ç°æ›´å¥½ï¼Œé«˜æ¯”ä¾‹æ—¶Node2Vecæ›´ä¼˜")
        
        if 'pa_performance' in report and 'n2v_performance' in report:
            pa_1_1 = report['pa_performance']['performance_at_1_1']
            n2v_1_1 = report['n2v_performance']['performance_at_1_1']
            if pa_1_1 and n2v_1_1:
                print(f"  â€¢ 1:1æ¯”ä¾‹æ€§èƒ½: PA({pa_1_1:.3f}) vs N2V({n2v_1_1:.3f})")


if __name__ == "__main__":
    main()
